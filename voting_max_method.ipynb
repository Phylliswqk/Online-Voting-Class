{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn import model_selection\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "from sklearn.utils import shuffle\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assist function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def main_voting(prob_predict, threshold, weight, voting_method):\n",
    "    \"\"\"\n",
    "    prob_predict: DataFrame, rows: number of instance, columns: number of models\n",
    "    threshold: float\n",
    "    weight: list(columns * 1) or None\n",
    "    voting_method: string, 'hard' or 'soft'\n",
    "    \"\"\"\n",
    "    model_number = len(prob_predict.columns)\n",
    "    instance_number = len(prob_predict)\n",
    "    y_pred = []\n",
    "    y_pred_prob = []\n",
    "        \n",
    "    if voting_method == 'hard':\n",
    "        for row in range(0, instance_number, 1):\n",
    "            pred_prob = list(prob_predict.iloc[row,])  \n",
    "            y_pred_all = [int(x > threshold) for x in pred_prob]\n",
    "            y_pred_hard = Counter(y_pred_all).most_common(1)[0][0]\n",
    "            y_pred_prob.append(float((Counter(y_pred_all).most_common(1)[0][1]) / model_number))\n",
    "            y_pred.append(y_pred_hard)\n",
    "            \n",
    "    elif voting_method == 'soft':\n",
    "        if weight == None:\n",
    "            for row in range(0, instance_number, 1):\n",
    "                pred_prob = list(prob_predict.iloc[row,])\n",
    "                y_pred_all = sum(pred_prob) / len(pred_prob)\n",
    "                y_pred_prob.append(y_pred_all)\n",
    "                y_pred_soft = int(y_pred_all > threshold)\n",
    "                y_pred.append(y_pred_soft)\n",
    "        \n",
    "        else:\n",
    "            for row in range(0, instance_number, 1):\n",
    "                pred_prob = list(prob_predict.iloc[row,])\n",
    "                y_pred_all = [pred_prob[i] * weight[i] for i in range(0, len(pred_prob), 1)]\n",
    "                y_pred_prob.append(sum(y_pred_all))\n",
    "                y_pred_soft_weight = int(sum(y_pred_all) > threshold)\n",
    "                #y_pred_soft_weight = int((sum(pred_prob) / len(pred_prob)) > threshold)\n",
    "                y_pred.append(y_pred_soft_weight)\n",
    "                \n",
    "    return {'y_pred':y_pred, 'y_pred_prob':y_pred_prob}\n",
    "\n",
    "def find_all_index(arr,item):\n",
    "    return [i for i,a in enumerate(arr) if a==item]\n",
    "\n",
    "def loss_func(pred, true, algo='square'):\n",
    "    \"\"\"calculate loss given true label and predicted label\n",
    "\n",
    "    Args:\n",
    "      true(int): true label [0, 1]\n",
    "      prediction(int): predicted lable [0, 1]\n",
    "      type(string): loss type\n",
    "    Returns:\n",
    "      loss value(float)\n",
    "    \"\"\"\n",
    "    if algo == 'square':\n",
    "        return (true-pred)**2\n",
    "    elif algo == 'relative-entropy':\n",
    "        # this will generate error\n",
    "        return true*np.log(true/pred)+(1-true)*np.log((1-true)/(1-pred))\n",
    "    elif algo == 'hellinger':\n",
    "        return 0.5*((np.sqrt(1-true)-np.sqrt(1-pred))**2+(np.sqrt(true)- np.sqrt(pred))**2)\n",
    "    elif algo == 'absolute':\n",
    "        return np.abs(true - pred)\n",
    "    \n",
    "\n",
    "def decision_prediction_function(pred_labels, weights, nita, c, loss_algo='square', pred_method='mean'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    vs = weights/np.sum(weights)\n",
    "    if pred_method=='mean':\n",
    "        pred_vovk = np.dot(vs, pred_labels)\n",
    "    elif pred_method=='vovk':\n",
    "        # this method is not the same as shown in the paper as the results following the formula in the pager doesn't seem right\n",
    "        delta = lambda x: -c*np.log(np.dot(vs, np.exp(-nita*np.apply_along_axis(loss_func, 0, pred_labels, x, loss_algo))))\n",
    "        pred_vovk = 0.5*((loss_func(delta(0),0))+(loss_func(delta(1),1)))\n",
    "    return pred_vovk\n",
    "    \n",
    "def tracking_the_best_expert(pred_labels, true_label, weights, alpha, nita, c, method='static-expert', loss_algo='square', pred_method='mean'):\n",
    "    y_hat = np.int(decision_prediction_function(pred_labels, weights, nita, c, loss_algo, pred_method)>0)\n",
    "    # loss update\n",
    "    intermediate_weights = weights*np.exp(-nita*np.apply_along_axis(loss_func, 0, pred_labels, true_label, loss_algo))\n",
    "#     intermediate_weights = intermediate_weights/np.sum(intermediate_weights)\n",
    "    n = np.int(pred_labels.shape[0])\n",
    "\n",
    "    if method == 'static-expert':\n",
    "        new_weights = intermediate_weights\n",
    "    elif method == 'fixed-share':\n",
    "        pool = np.sum(alpha*intermediate_weights)\n",
    "        new_weights = (1-alpha)*intermediate_weights+(pool - alpha*intermediate_weights)/(n-1)\n",
    "    elif method == 'variable-share':\n",
    "        frac = lambda x: (1-alpha)**loss_func(x, true_label, loss_algo)\n",
    "        temp = np.apply_along_axis(frac, 0, pred_labels)\n",
    "        pool = np.sum((1-temp)*intermediate_weights)\n",
    "        new_weights = temp*intermediate_weights+(pool-(1-temp)*intermediate_weights)/(n-1)\n",
    "        \n",
    "    new_weights = new_weights/np.sum(new_weights)\n",
    "#     print('total loss:{}'.format(np.sum(np.apply_along_axis(loss_func, 0, pred_labels, true_label, loss_algo))))\n",
    "    return new_weights, np.sum(np.apply_along_axis(loss_func, 0, pred_labels, true_label, loss_algo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting(data, split_ratio, threshold):\n",
    "#     result = {}\n",
    "    data_length = len(data)\n",
    "    \n",
    "    model_major_weight = [1] * (len(data.columns) - 1)\n",
    "    \n",
    "    train_ratio, validation_ratio, test_ratio =  split_ratio[0], split_ratio[1], split_ratio[2]\n",
    "    validation_data = data.loc[data_length*train_ratio : data_length*validation_ratio]\n",
    "    test_data = data.loc[data_length*validation_ratio:]\n",
    "    \n",
    "    validation_y = validation_data['y']\n",
    "    validation_x = validation_data.drop(['y'], axis = 1)\n",
    "    test_y = test_data['y']\n",
    "    test_x = test_data.drop(['y'], axis = 1)\n",
    "    \n",
    "    all_model_weight = []\n",
    "    all_model_weight.append(copy.deepcopy(model_major_weight))\n",
    "    validation_pred = []\n",
    "    count1 = count0 = 0\n",
    "    beta = 0.90\n",
    "    \n",
    "    for row_num in range(0, len(validation_x), 1):\n",
    "        x = []\n",
    "        for i in range(0, len(validation_x.columns), 1):\n",
    "            x.append(int(validation_x.iloc[row_num,i] > threshold))\n",
    "        index1 = find_all_index(x, 1)\n",
    "        index0 = find_all_index(x, 0)\n",
    "        #print(index0)\n",
    "        if len(index1) > 0:\n",
    "            count1 = sum([all_model_weight[-1][i] for i in index1])\n",
    "        if len(index0) > 0:\n",
    "            count0 = sum([all_model_weight[-1][i] for i in index0])\n",
    "        if count0 > count1:\n",
    "            prediction = 0\n",
    "        elif count0 < count1:\n",
    "            prediction = 1\n",
    "        else:\n",
    "            prediction = np.random.randint(0,2)\n",
    "        validation_pred.append(prediction)\n",
    "        for i in range(0, len(model_major_weight), 1):\n",
    "            if x[i] != prediction:\n",
    "                model_major_weight[i] = beta * model_major_weight[i]\n",
    "        all_model_weight.append(copy.deepcopy([i / sum(model_major_weight) for i in model_major_weight]))\n",
    "    \n",
    "    voting = main_voting(test_x, threshold, all_model_weight[-1], 'soft')\n",
    "    voting['test_y'] = list(test_y)\n",
    "    voting['final_weight'] = all_model_weight[-1]\n",
    "    voting['weight_list'] = all_model_weight\n",
    "    return voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random_majority_voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_majority_voting(data, split_ratio, threshold):\n",
    "    from numpy.random import choice\n",
    "    \n",
    "    data_length = len(data)\n",
    "    model_major_weight = [1] * (len(data.columns) - 1)\n",
    "    \n",
    "    train_ratio, validation_ratio, test_ratio =  split_ratio[0], split_ratio[1], split_ratio[2]\n",
    "    validation_data = data.loc[data_length*train_ratio : data_length*validation_ratio]\n",
    "    test_data = data.loc[data_length*validation_ratio:]\n",
    "    \n",
    "    validation_y = validation_data['y']\n",
    "    validation_x = validation_data.drop(['y'], axis = 1)\n",
    "    test_y = test_data['y']\n",
    "    test_x = test_data.drop(['y'], axis = 1)\n",
    "    \n",
    "    beta = 0.90\n",
    "    model_prediction = []\n",
    "    all_model_weight1 = []\n",
    "    all_model_weight1.append(copy.deepcopy(model_major_weight))\n",
    "    for row_num in range(0, len(validation_x), 1):\n",
    "        x = []\n",
    "        choose = [a for a in range(0, len(validation_x.columns), 1)]\n",
    "        weights = all_model_weight1[-1]\n",
    "        weights1 = [float(i / sum(all_model_weight1[-1])) for i in all_model_weight1[-1]]\n",
    "        i = choice(choose, p=weights1)\n",
    "        model_pred_single = validation_x.iloc[row_num,i]\n",
    "        if model_pred_single != validation_y.iloc[row_num]:\n",
    "            weights[i] = beta * weights[i]\n",
    "        all_model_weight1.append(copy.deepcopy(weights))\n",
    "\n",
    "    all_model_weight1[-1] = [i / sum(all_model_weight1[-1]) for i in all_model_weight1[-1]]\n",
    "    voting = main_voting(test_x, threshold, all_model_weight1[-1], 'soft')\n",
    "    voting['test_y'] = list(test_y)\n",
    "    voting['final_weight'] = all_model_weight1[-1]\n",
    "    voting['weight_list'] = all_model_weight1\n",
    "    return voting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perceptron_voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_voting(data, split_ratio, threshold):\n",
    "    data_length = len(data)\n",
    "    model_major_weight = [1] * (len(data.columns) - 1)\n",
    "    \n",
    "    train_ratio, validation_ratio, test_ratio =  split_ratio[0], split_ratio[1], split_ratio[2]\n",
    "    validation_data = data.loc[data_length*train_ratio : data_length*validation_ratio]\n",
    "    test_data = data.loc[data_length*validation_ratio:]\n",
    "    \n",
    "    validation_y = validation_data['y']\n",
    "    validation_x = validation_data.drop(['y'], axis = 1)\n",
    "    test_y = test_data['y']\n",
    "    test_x = test_data.drop(['y'], axis = 1)\n",
    "\n",
    "    for row_num in range(len(validation_x)):\n",
    "        for i in range(len(validation_x.columns)):\n",
    "            validation_x.iloc[row_num,i] = int(validation_x.iloc[row_num,i] > 0.5)\n",
    "    perceptron_df = validation_x\n",
    "    weight_per = []\n",
    "\n",
    "    for random_seed in [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]:\n",
    "        perceptron_clf = Perceptron(tol=1e-3, random_state=random_seed)\n",
    "        perceptron_clf.fit(perceptron_df, validation_y)\n",
    "        weight_per.append(perceptron_clf.coef_)\n",
    "        #y_predict_per = perceptron_clf.predict()\n",
    "    weight_per1 = list(np.mean(weight_per, axis = 0)[0])\n",
    "    weight_per2 = [i/sum(weight_per1) for i in weight_per1]\n",
    "    \n",
    "    voting = main_voting(test_x, threshold, weight_per2, 'soft')\n",
    "    voting['test_y'] = list(test_y)\n",
    "    voting['final_weight'] = weight_per2\n",
    "    voting['weight_list'] = weight_per2\n",
    "    return voting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best_Expert using fixed-share chosen function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_expert_fixedshare(data, split_ratio, threshold):\n",
    "    data_length = len(data)\n",
    "    model_major_weight_track = [1] * (len(data.columns) - 1)\n",
    "    \n",
    "    train_ratio, validation_ratio, test_ratio =  split_ratio[0], split_ratio[1], split_ratio[2]\n",
    "    validation_data = data.loc[data_length*train_ratio : data_length*validation_ratio]\n",
    "    test_data = data.loc[data_length*validation_ratio:] \n",
    "    validation_y = validation_data['y']\n",
    "    validation_x = validation_data.drop(['y'], axis = 1)\n",
    "    test_y = test_data['y']\n",
    "    test_x = test_data.drop(['y'], axis = 1)\n",
    "\n",
    "    nita = 2\n",
    "    c = 1/nita\n",
    "    alpha = 1/1000\n",
    "    total_loss = 0\n",
    "    model_prediction = []\n",
    "    model_number = []\n",
    "    \n",
    "    for row_num in range(len(validation_x)):\n",
    "        for i in range(len(validation_x.columns)):\n",
    "            validation_x.iloc[row_num,i] = int(validation_x.iloc[row_num,i] > 0.5)\n",
    "    \n",
    "    all_model_weight_track = []\n",
    "    all_model_weight_track.append(copy.deepcopy(model_major_weight_track))\n",
    "    validation_pred = []\n",
    "    for row_num in range(0, len(validation_x), 1):\n",
    "        pred_labels = np.array(validation_x.iloc[row_num,:])\n",
    "        true_label = validation_y.iloc[row_num]\n",
    "        model_major_weight_track, loss=tracking_the_best_expert(pred_labels, true_label, model_major_weight_track, alpha, nita, c, 'fixed-share', 'square', 'mean')\n",
    "        all_model_weight_track.append(copy.deepcopy(list(model_major_weight_track)))\n",
    "        total_loss += loss\n",
    "    voting = main_voting(test_x, threshold, all_model_weight_track[-1], 'soft')\n",
    "    voting['test_y'] = list(test_y)\n",
    "    voting['final_weight'] = all_model_weight_track[-1]\n",
    "    voting['weight_list'] = all_model_weight_track\n",
    "    return voting    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best_Expert using variable-share chosen function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_expert_variableshare(data, split_ratio, threshold):\n",
    "    data_length = len(data)\n",
    "    model_major_weight_track = [1] * (len(data.columns) - 1)\n",
    "    \n",
    "    train_ratio, validation_ratio, test_ratio =  split_ratio[0], split_ratio[1], split_ratio[2]\n",
    "    validation_data = data.loc[data_length*train_ratio : data_length*validation_ratio]\n",
    "    test_data = data.loc[data_length*validation_ratio:] \n",
    "    validation_y = validation_data['y']\n",
    "    validation_x = validation_data.drop(['y'], axis = 1)\n",
    "    test_y = test_data['y']\n",
    "    test_x = test_data.drop(['y'], axis = 1)\n",
    "\n",
    "    nita = 2\n",
    "    c = 1/nita\n",
    "    alpha = 1/1000\n",
    "    total_loss = 0\n",
    "    model_prediction = []\n",
    "    model_number = []\n",
    "    \n",
    "    for row_num in range(len(validation_x)):\n",
    "        for i in range(len(validation_x.columns)):\n",
    "            validation_x.iloc[row_num,i] = int(validation_x.iloc[row_num,i] > 0.5)\n",
    "    \n",
    "    all_model_weight_track = []\n",
    "    all_model_weight_track.append(copy.deepcopy(model_major_weight_track))\n",
    "    validation_pred = []\n",
    "    for row_num in range(0, len(validation_x), 1):\n",
    "        pred_labels = np.array(validation_x.iloc[row_num,:])\n",
    "        true_label = validation_y.iloc[row_num]\n",
    "        model_major_weight_track, loss=tracking_the_best_expert(pred_labels, true_label, model_major_weight_track, alpha, nita, c, 'variable-share', 'square', 'mean')\n",
    "        all_model_weight_track.append(copy.deepcopy(list(model_major_weight_track)))\n",
    "        total_loss += loss\n",
    "    voting = main_voting(test_x, threshold, all_model_weight_track[-1], 'soft')\n",
    "    voting['test_y'] = list(test_y)\n",
    "    voting['final_weight'] = all_model_weight_track[-1]\n",
    "    voting['weight_list'] = all_model_weight_track\n",
    "    return voting    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best_Expert using static-expert chosen function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_expert_staticexpert(data, split_ratio, threshold):\n",
    "    data_length = len(data)\n",
    "    model_major_weight_track = [1] * (len(data.columns) - 1)\n",
    "    \n",
    "    train_ratio, validation_ratio, test_ratio =  split_ratio[0], split_ratio[1], split_ratio[2]\n",
    "    validation_data = data.loc[data_length*train_ratio : data_length*validation_ratio]\n",
    "    test_data = data.loc[data_length*validation_ratio:] \n",
    "    validation_y = validation_data['y']\n",
    "    validation_x = validation_data.drop(['y'], axis = 1)\n",
    "    test_y = test_data['y']\n",
    "    test_x = test_data.drop(['y'], axis = 1)\n",
    "\n",
    "    nita = 2\n",
    "    c = 1/nita\n",
    "    alpha = 1/1000\n",
    "    total_loss = 0\n",
    "    model_prediction = []\n",
    "    model_number = []\n",
    "    \n",
    "    for row_num in range(len(validation_x)):\n",
    "        for i in range(len(validation_x.columns)):\n",
    "            validation_x.iloc[row_num,i] = int(validation_x.iloc[row_num,i] > 0.5)\n",
    "    \n",
    "    all_model_weight_track = []\n",
    "    all_model_weight_track.append(copy.deepcopy(model_major_weight_track))\n",
    "    validation_pred = []\n",
    "    for row_num in range(0, len(validation_x), 1):\n",
    "        pred_labels = np.array(validation_x.iloc[row_num,:])\n",
    "        true_label = validation_y.iloc[row_num]\n",
    "        model_major_weight_track, loss=tracking_the_best_expert(pred_labels, true_label, model_major_weight_track, alpha, nita, c, 'static-expert', 'square', 'mean')\n",
    "        all_model_weight_track.append(copy.deepcopy(list(model_major_weight_track)))\n",
    "        total_loss += loss\n",
    "    voting = main_voting(test_x, threshold, all_model_weight_track[-1], 'soft')\n",
    "    voting['test_y'] = list(test_y)\n",
    "    voting['final_weight'] = all_model_weight_track[-1]\n",
    "    voting['weight_list'] = all_model_weight_track\n",
    "    return voting    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[0.6,0.4,0.3,0.4,0],[0.3,0.8,0.9,0.9,1],[0.2,0.9,0.2,0.4,0],[0.2,0.4,0.9,0.4,0],[0.2,0.4,0.2,0.4,0],[0.3,0.8,0.9,0.9,1],[0.3,0.8,0.9,0.9,1],[0.2,0.4,0.2,0.4,0],[0.3,0.8,0.1,0.9,1],[0.3,0.8,0.1,0.9,1],[0.3,0.8,0.1,0.9,1],[0.3,0.8,0.1,0.9,1],[0.3,0.8,0.1,0.9,1],[0.3,0.8,0.1,0.9,1]]\n",
    "x_test = pd.DataFrame(x, columns = ['1','2','3','4','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y_pred': [0, 1, 1, 1, 1, 1, 1], 'y_pred_prob': [0.37615941559557653, 0.7969801711656775, 0.7969801711656775, 0.7969801711656775, 0.7969801711656775, 0.7969801711656775, 0.7969801711656775], 'test_y': [0, 1, 1, 1, 1, 1, 1], 'final_weight': [0.014209336618611042, 0.10499358540350652, 0.10499358540350653, 0.775803492574376], 'weight_list': [[1, 1, 1, 1], [0.3189451556733346, 0.04316453297999626, 0.3189451556733346, 0.3189451556733346], [0.4403985389889412, 0.05960146101105877, 0.05960146101105878, 0.4403985389889412], [0.4403985389889412, 0.05960146101105877, 0.05960146101105878, 0.4403985389889412], [0.09625513525746872, 0.0962551352574687, 0.09625513525746872, 0.7112345942275938], [0.014209336618611042, 0.10499358540350652, 0.10499358540350653, 0.775803492574376], [0.014209336618611042, 0.10499358540350652, 0.10499358540350653, 0.775803492574376]]}\n"
     ]
    }
   ],
   "source": [
    "print(best_expert_staticexpert(x_test, [0.1,0.5,0.4], 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class majority_voting:\n",
    "    def __init__(self, threshold = 0.4):\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "#         check_classification_targets(y)\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        model_major_weight = [1 for cols in range(len(X.columns))]\n",
    "        all_model_weight = []\n",
    "        all_model_weight.append(copy.deepcopy(model_major_weight))\n",
    "        #validation_pred = []\n",
    "        count1 = count0 = 0\n",
    "        beta = 0.90\n",
    "        for row_num in range(0, len(X), 1):\n",
    "            x1 = []\n",
    "            for i in range(0, len(X.columns), 1):\n",
    "                x1.append(int(X.iloc[row_num,i] > self.threshold))\n",
    "            index1 = find_all_index(x1, 1)\n",
    "            index0 = find_all_index(x1, 0)\n",
    "            if len(index1) > 0:\n",
    "                count1 = sum([all_model_weight[-1][i] for i in index1])\n",
    "            if len(index0) > 0:\n",
    "                count0 = sum([all_model_weight[-1][i] for i in index0])\n",
    "            if count0 > count1:\n",
    "                prediction = 0\n",
    "            elif count0 < count1:\n",
    "                prediction = 1\n",
    "            else:\n",
    "                prediction = np.random.randint(0,2)\n",
    "            #validation_pred.append(prediction)\n",
    "            print()\n",
    "            for i in range(0, len(model_major_weight), 1):\n",
    "                if x1[i] != prediction:\n",
    "                    model_major_weight[i] = beta * model_major_weight[i]\n",
    "            all_model_weight.append(copy.deepcopy([i / sum(model_major_weight) for i in model_major_weight]))\n",
    "        self.weight = all_model_weight[-1]\n",
    "        self.weight_list = all_model_weight\n",
    "        \n",
    "    def predict(self, X):\n",
    "        model_number = len(X.columns)\n",
    "        instance_number = len(X)\n",
    "        y_pred = []\n",
    "        \n",
    "        for row in range(0, instance_number, 1):\n",
    "            pred_prob = list(X.iloc[row,])\n",
    "            y_pred_all = [pred_prob[i] * self.weight[i] for i in range(0, len(pred_prob), 1)]\n",
    "            y_pred_soft_weight = int(sum(y_pred_all) > self.threshold)\n",
    "            y_pred.append(y_pred_soft_weight)       \n",
    "        return y_pred\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        model_number = len(X.columns)\n",
    "        instance_number = len(X)\n",
    "        y_pred_prob = []\n",
    "        for row in range(0, instance_number, 1):\n",
    "            pred_prob = list(X.iloc[row,])\n",
    "            y_pred_all = [pred_prob[i] * self.weight[i] for i in range(0, len(pred_prob), 1)]\n",
    "            y_pred_prob.append([1 - sum(y_pred_all), sum(y_pred_all)])\n",
    "            \n",
    "        return y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class random_majority_voting:\n",
    "    def __init__(self, threshold = 0.4):\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        from numpy.random import choice\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        model_major_weight = [1 for cols in range(len(X.columns))]\n",
    "        all_model_weight = []\n",
    "        all_model_weight.append(copy.deepcopy(model_major_weight))\n",
    "        beta = 0.90\n",
    "        \n",
    "        for row_num in range(0, len(X), 1):\n",
    "            x1 = []\n",
    "            choose = [a for a in range(0, len(X.columns), 1)]\n",
    "            weights = all_model_weight[-1]\n",
    "            weights1 = [float(i / sum(all_model_weight[-1])) for i in all_model_weight[-1]]\n",
    "            i = choice(choose, p=weights1)\n",
    "            model_pred_single = X.iloc[row_num,i]\n",
    "            if model_pred_single != validation_y.iloc[row_num]:\n",
    "                weights[i] = beta * weights[i]\n",
    "            all_model_weight.append(copy.deepcopy([i / sum(weights) for i in weights]))\n",
    "        self.weight = all_model_weight[-1]\n",
    "        self.weight_list = all_model_weight\n",
    "        \n",
    "    def predict(self, X):\n",
    "        model_number = len(X.columns)\n",
    "        instance_number = len(X)\n",
    "        y_pred = []\n",
    "        \n",
    "        for row in range(0, instance_number, 1):\n",
    "            pred_prob = list(X.iloc[row,])\n",
    "            y_pred_all = [pred_prob[i] * self.weight[i] for i in range(0, len(pred_prob), 1)]\n",
    "            y_pred_soft_weight = int(sum(y_pred_all) > self.threshold)\n",
    "            y_pred.append(y_pred_soft_weight)       \n",
    "        return y_pred\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        model_number = len(X.columns)\n",
    "        instance_number = len(X)\n",
    "        y_pred_prob = []\n",
    "        for row in range(0, instance_number, 1):\n",
    "            pred_prob = list(X.iloc[row,])\n",
    "            y_pred_all = [pred_prob[i] * self.weight[i] for i in range(0, len(pred_prob), 1)]\n",
    "            y_pred_prob.append([1 - sum(y_pred_all), sum(y_pred_all)])\n",
    "            \n",
    "        return y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class perceptron_voting:\n",
    "    def __init__(self, threshold = 0.4):\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        from numpy.random import choice\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        model_major_weight = [1 for cols in range(len(X.columns))]\n",
    "        all_model_weight = []\n",
    "        all_model_weight.append(copy.deepcopy(model_major_weight))\n",
    "        beta = 0.90\n",
    "        \n",
    "        for row_num in range(len(X)):\n",
    "            for i in range(len(X.columns)):\n",
    "                X.iloc[row_num,i] = int(X.iloc[row_num,i] > self.threshold)\n",
    "        perceptron_df = X\n",
    "        weight_per = []\n",
    "        for random_seed in [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]:\n",
    "            perceptron_clf = Perceptron(tol=1e-3, random_state=random_seed)\n",
    "            perceptron_clf.fit(perceptron_df, y)\n",
    "            print(perceptron_clf.predict(perceptron_df))\n",
    "            weight_per.append(perceptron_clf.coef_)\n",
    "        #y_predict_per = perceptron_clf.predict()\n",
    "        weight_per1 = list(np.mean(weight_per, axis = 0)[0])\n",
    "        weight_per2 = [i/sum(weight_per1) for i in weight_per1]\n",
    "    \n",
    "        self.weight = weight_per2\n",
    "        self.weight_list = weight_per2\n",
    "        \n",
    "    def predict(self, X):\n",
    "        model_number = len(X.columns)\n",
    "        instance_number = len(X)\n",
    "        y_pred = []\n",
    "        \n",
    "        for row in range(0, instance_number, 1):\n",
    "            pred_prob = list(X.iloc[row,])\n",
    "            y_pred_all = [pred_prob[i] * self.weight[i] for i in range(0, len(pred_prob), 1)]\n",
    "            y_pred_soft_weight = int(sum(y_pred_all) > self.threshold)\n",
    "            y_pred.append(y_pred_soft_weight)       \n",
    "        return y_pred\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        import math\n",
    "        model_number = len(X.columns)\n",
    "        instance_number = len(X)\n",
    "        y_pred_prob = []\n",
    "        for row in range(0, instance_number, 1):\n",
    "            pred_prob = list(X.iloc[row,])\n",
    "            y_pred_all = [pred_prob[i] * self.weight[i] for i in range(0, len(pred_prob), 1)]\n",
    "            prob1 = 1 /(1.1 + math.exp(-sum(y_pred_all)))\n",
    "            y_pred_prob.append([1 - prob1, prob1])\n",
    "            \n",
    "        return y_pred_prob     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class best_expert:\n",
    "    \"\"\"\n",
    "    init:\n",
    "        algo: 'square','relative-entropy','hellinger','absolute' is used for loss function\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, threshold = 0.4, method ='static-expert', loss_algo='square', pred_method='mean'):\n",
    "        self.threshold = threshold\n",
    "        self.method = method\n",
    "        self.loss_algo = loss_algo\n",
    "        self.pred_method = pred_method\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        from numpy.random import choice\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        model_major_weight = [1 for cols in range(len(X.columns))]\n",
    "        all_model_weight = []\n",
    "        all_model_weight.append(copy.deepcopy(model_major_weight))\n",
    "        nita = 2\n",
    "        c = 1/nita\n",
    "        alpha = 1/1000\n",
    "        total_loss = 0\n",
    "        \n",
    "        for row_num in range(len(X)):\n",
    "            for i in range(len(X.columns)):\n",
    "                X.iloc[row_num,i] = int(X.iloc[row_num,i] > self.threshold)\n",
    "\n",
    "        validation_pred = []\n",
    "        for row_num in range(0, len(X), 1):\n",
    "            pred_labels = np.array(X.iloc[row_num,:])\n",
    "            true_label = y.iloc[row_num]\n",
    "            #print(pred_labels, true_label)\n",
    "            model_major_weight, loss = self.tracking_the_best_expert(pred_labels, true_label, model_major_weight, alpha, nita, c, self.method, self.loss_algo, self.pred_method)\n",
    "            all_model_weight.append(copy.deepcopy(list(model_major_weight)))\n",
    "            total_loss += loss\n",
    "\n",
    "        self.weight = all_model_weight[-1]\n",
    "        self.weight_list = all_model_weight\n",
    "        self.total_loss = total_loss\n",
    "        \n",
    "    def predict(self, X):\n",
    "        model_number = len(X.columns)\n",
    "        instance_number = len(X)\n",
    "        y_pred = []\n",
    "        \n",
    "        for row in range(0, instance_number, 1):\n",
    "            pred_prob = list(X.iloc[row,])\n",
    "            y_pred_all = [pred_prob[i] * self.weight[i] for i in range(0, len(pred_prob), 1)]\n",
    "            y_pred_soft_weight = int(sum(y_pred_all) > self.threshold)\n",
    "            y_pred.append(y_pred_soft_weight)       \n",
    "        return y_pred\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        model_number = len(X.columns)\n",
    "        instance_number = len(X)\n",
    "        y_pred_prob = []\n",
    "        for row in range(0, instance_number, 1):\n",
    "            pred_prob = list(X.iloc[row,])\n",
    "            y_pred_all = [pred_prob[i] * self.weight[i] for i in range(0, len(pred_prob), 1)]\n",
    "            y_pred_prob.append([1 - sum(y_pred_all), sum(y_pred_all)])\n",
    "            \n",
    "        return y_pred_prob\n",
    "    \n",
    "    def loss_func(self, pred, true, algo='square'):\n",
    "        \"\"\"calculate loss given true label and predicted label\n",
    "\n",
    "        Args:\n",
    "          true(int): true label [0, 1]\n",
    "          prediction(int): predicted lable [0, 1]\n",
    "          type(string): loss type\n",
    "        Returns:\n",
    "          loss value(float)\n",
    "        \"\"\"\n",
    "        if algo == 'square':\n",
    "            return (true-pred)**2\n",
    "        elif algo == 'relative-entropy':\n",
    "            # this will generate error\n",
    "            return true*np.log(true/pred)+(1-true)*np.log((1-true)/(1-pred))\n",
    "        elif algo == 'hellinger':\n",
    "            return 0.5*((np.sqrt(1-true)-np.sqrt(1-pred))**2+(np.sqrt(true)- np.sqrt(pred))**2)\n",
    "        elif algo == 'absolute':\n",
    "            return np.abs(true - pred)\n",
    "    \n",
    "\n",
    "    def decision_prediction_function(self, pred_labels, weights, nita, c, loss_algo='square', pred_method='mean'):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        vs = weights/np.sum(weights)\n",
    "        if pred_method=='mean':\n",
    "            pred_vovk = np.dot(vs, pred_labels)\n",
    "        elif pred_method=='vovk':\n",
    "            # this method is not the same as shown in the paper as the results following the formula in the pager doesn't seem right\n",
    "            delta = lambda x: -c*np.log(np.dot(vs, np.exp(-nita*np.apply_along_axis(self.loss_func, 0, pred_labels, x, loss_algo))))\n",
    "            pred_vovk = 0.5*((self.loss_func(delta(0),0))+(self.loss_func(delta(1),1)))\n",
    "        return pred_vovk\n",
    "\n",
    "    def tracking_the_best_expert(self, pred_labels, true_label, weights, alpha, nita, c, method='static-expert', loss_algo='square', pred_method='mean'):\n",
    "        y_hat = np.int(self.decision_prediction_function(pred_labels, weights, nita, c, loss_algo, pred_method)>0)\n",
    "        # loss update\n",
    "        intermediate_weights = weights*np.exp(-nita*np.apply_along_axis(self.loss_func, 0, pred_labels, true_label, loss_algo))\n",
    "    #     intermediate_weights = intermediate_weights/np.sum(intermediate_weights)\n",
    "        n = np.int(pred_labels.shape[0])\n",
    "\n",
    "        if method == 'static-expert':\n",
    "            new_weights = intermediate_weights\n",
    "        elif method == 'fixed-share':\n",
    "            pool = np.sum(alpha*intermediate_weights)\n",
    "            new_weights = (1-alpha)*intermediate_weights+(pool - alpha*intermediate_weights)/(n-1)\n",
    "        elif method == 'variable-share':\n",
    "            frac = lambda x: (1-alpha)**self.loss_func(x, true_label, loss_algo)\n",
    "            temp = np.apply_along_axis(frac, 0, pred_labels)\n",
    "            pool = np.sum((1-temp)*intermediate_weights)\n",
    "            new_weights = temp*intermediate_weights+(pool-(1-temp)*intermediate_weights)/(n-1)\n",
    "\n",
    "        new_weights = new_weights/np.sum(new_weights)\n",
    "    #     print('total loss:{}'.format(np.sum(np.apply_along_axis(loss_func, 0, pred_labels, true_label, loss_algo))))\n",
    "        return new_weights, np.sum(np.apply_along_axis(self.loss_func, 0, pred_labels, true_label, loss_algo))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
